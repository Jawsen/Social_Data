{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             PdId  IncidntNum  Incident Code       Category  \\\n",
      "0   4133422003074    41334220           3074        ROBBERY   \n",
      "1   5118535807021    51185358           7021  VEHICLE THEFT   \n",
      "2   4018830907021    40188309           7021  VEHICLE THEFT   \n",
      "3  11014543126030   110145431          26030          ARSON   \n",
      "4  10108108004134   101081080           4134        ASSAULT   \n",
      "\n",
      "                Descript DayOfWeek        Date   Time PdDistrict Resolution  \\\n",
      "0  ROBBERY, BODILY FORCE    Monday  11/22/2004  17:50  INGLESIDE       NONE   \n",
      "1      STOLEN AUTOMOBILE   Tuesday  10/18/2005  20:00       PARK       NONE   \n",
      "2      STOLEN AUTOMOBILE    Sunday  02/15/2004  02:00   SOUTHERN       NONE   \n",
      "3                  ARSON    Friday  02/18/2011  05:27  INGLESIDE       NONE   \n",
      "4                BATTERY    Sunday  11/21/2010  17:00   SOUTHERN       NONE   \n",
      "\n",
      "   ... Fix It Zones as of 2017-11-06  2 2  DELETE - HSOC Zones 2 2  \\\n",
      "0  ...                                NaN                      NaN   \n",
      "1  ...                                NaN                      NaN   \n",
      "2  ...                                NaN                      NaN   \n",
      "3  ...                                NaN                      NaN   \n",
      "4  ...                                NaN                      NaN   \n",
      "\n",
      "   Fix It Zones as of 2018-02-07 2 2  \\\n",
      "0                                NaN   \n",
      "1                                NaN   \n",
      "2                                NaN   \n",
      "3                                NaN   \n",
      "4                                NaN   \n",
      "\n",
      "  CBD, BID and GBD Boundaries as of 2017 2 2  \\\n",
      "0                                        NaN   \n",
      "1                                        NaN   \n",
      "2                                        NaN   \n",
      "3                                        NaN   \n",
      "4                                        NaN   \n",
      "\n",
      "   Areas of Vulnerability, 2016 2 2  Central Market/Tenderloin Boundary 2 2  \\\n",
      "0                               NaN                                     NaN   \n",
      "1                               NaN                                     NaN   \n",
      "2                               NaN                                     NaN   \n",
      "3                               1.0                                     NaN   \n",
      "4                               2.0                                     NaN   \n",
      "\n",
      "   Central Market/Tenderloin Boundary Polygon - Updated 2 2  \\\n",
      "0                                                NaN          \n",
      "1                                                NaN          \n",
      "2                                                NaN          \n",
      "3                                                NaN          \n",
      "4                                                NaN          \n",
      "\n",
      "   HSOC Zones as of 2018-06-05 2 2  OWED Public Spaces 2 2  Neighborhoods 2  \n",
      "0                              NaN                     NaN              NaN  \n",
      "1                              NaN                     NaN              NaN  \n",
      "2                              NaN                     NaN              NaN  \n",
      "3                              NaN                     NaN             94.0  \n",
      "4                              NaN                     NaN             32.0  \n",
      "\n",
      "[5 rows x 35 columns]\n",
      "        Incident Datetime Incident Date Incident Time  Incident Year  \\\n",
      "0  2023/03/01 05:02:00 AM    2023/03/01         05:02           2023   \n",
      "1  2023/03/13 10:59:00 AM    2023/03/13         10:59           2023   \n",
      "2  2023/03/14 06:44:00 PM    2023/03/14         18:44           2023   \n",
      "3  2023/02/15 03:00:00 AM    2023/02/15         03:00           2023   \n",
      "4  2023/03/13 11:26:00 AM    2023/03/13         11:26           2023   \n",
      "\n",
      "  Incident Day of Week         Report Datetime        Row ID  Incident ID  \\\n",
      "0            Wednesday  2023/03/11 03:40:00 PM  125379506374      1253795   \n",
      "1               Monday  2023/03/13 11:00:00 AM  125355107041      1253551   \n",
      "2              Tuesday  2023/03/14 06:45:00 PM  125402407041      1254024   \n",
      "3            Wednesday  2023/03/11 04:55:00 PM  125378606372      1253786   \n",
      "4               Monday  2023/03/13 01:37:00 PM  125419506244      1254195   \n",
      "\n",
      "   Incident Number  CAD Number  ... Longitude Point Neighborhoods  \\\n",
      "0        236046151         NaN  ...       NaN   NaN           NaN   \n",
      "1        230174885         NaN  ...       NaN   NaN           NaN   \n",
      "2        230176728         NaN  ...       NaN   NaN           NaN   \n",
      "3        236046123         NaN  ...       NaN   NaN           NaN   \n",
      "4        236046850         NaN  ...       NaN   NaN           NaN   \n",
      "\n",
      "   ESNCAG - Boundary File  \\\n",
      "0                     NaN   \n",
      "1                     NaN   \n",
      "2                     NaN   \n",
      "3                     NaN   \n",
      "4                     NaN   \n",
      "\n",
      "  Central Market/Tenderloin Boundary Polygon - Updated  \\\n",
      "0                                                NaN     \n",
      "1                                                NaN     \n",
      "2                                                NaN     \n",
      "3                                                NaN     \n",
      "4                                                NaN     \n",
      "\n",
      "  Civic Center Harm Reduction Project Boundary HSOC Zones as of 2018-06-05  \\\n",
      "0                                          NaN                         NaN   \n",
      "1                                          NaN                         NaN   \n",
      "2                                          NaN                         NaN   \n",
      "3                                          NaN                         NaN   \n",
      "4                                          NaN                         NaN   \n",
      "\n",
      "  Invest In Neighborhoods (IIN) Areas Current Supervisor Districts  \\\n",
      "0                                 NaN                          NaN   \n",
      "1                                 NaN                          NaN   \n",
      "2                                 NaN                          NaN   \n",
      "3                                 NaN                          NaN   \n",
      "4                                 NaN                          NaN   \n",
      "\n",
      "   Current Police Districts  \n",
      "0                       NaN  \n",
      "1                       NaN  \n",
      "2                       NaN  \n",
      "3                       NaN  \n",
      "4                       NaN  \n",
      "\n",
      "[5 rows x 35 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define correct file paths (update if necessary)\n",
    "file1 = \"Data/Police_Department_Incident_Reports__Historical_2003_to_May_2018.csv\"\n",
    "file2 = \"Data/Police_Department_Incident_Reports__2018_to_Present.csv\"\n",
    "\n",
    "# Load datasets\n",
    "df1 = pd.read_csv(file1, low_memory=False)\n",
    "df2 = pd.read_csv(file2, low_memory=False)\n",
    "\n",
    "# Check first few rows\n",
    "print(df1.head())\n",
    "print(df2.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Only relevant columns kept.\n",
      "âœ… Dates converted and filtered!\n",
      "df1 data types:\n",
      " Incident Date           datetime64[ns]\n",
      "Incident Time                   object\n",
      "Incident Day of Week            object\n",
      "Incident Category               object\n",
      "Incident Description            object\n",
      "Police District                 object\n",
      "Latitude                       float64\n",
      "Longitude                      float64\n",
      "dtype: object\n",
      "df2 data types:\n",
      " Incident Date           datetime64[ns]\n",
      "Incident Time                   object\n",
      "Incident Day of Week            object\n",
      "Incident Category               object\n",
      "Incident Description            object\n",
      "Police District                 object\n",
      "Latitude                       float64\n",
      "Longitude                      float64\n",
      "dtype: object\n",
      "âœ… Datasets merged successfully! Total rows: 2897375\n",
      "âœ… Removed 40373 duplicate rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lr/_ynnd4hs17b6vnnx6lbz3hzh0000gn/T/ipykernel_22196/2153475292.py:89: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_final[\"Latitude\"].fillna(df_final[\"Latitude\"].median(), inplace=True)\n",
      "/var/folders/lr/_ynnd4hs17b6vnnx6lbz3hzh0000gn/T/ipykernel_22196/2153475292.py:90: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_final[\"Longitude\"].fillna(df_final[\"Longitude\"].median(), inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Missing values handled. Total remaining rows: 2856300\n",
      "ðŸŽ‰ Final cleaned dataset saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define correct file paths\n",
    "file1 = \"Data/Police_Department_Incident_Reports__Historical_2003_to_May_2018.csv\"\n",
    "file2 = \"Data/Police_Department_Incident_Reports__2018_to_Present.csv\"\n",
    "\n",
    "# âœ… Load datasets\n",
    "df1 = pd.read_csv(file1, low_memory=False)\n",
    "df2 = pd.read_csv(file2, low_memory=False)\n",
    "\n",
    "# âœ… Step 1: Remove Duplicate Columns in df2\n",
    "df2 = df2.loc[:, ~df2.columns.duplicated()]\n",
    "\n",
    "# âœ… Step 2: Trim Column Names (Remove Extra Spaces)\n",
    "df1.columns = df1.columns.str.strip()\n",
    "df2.columns = df2.columns.str.strip()\n",
    "\n",
    "# âœ… Step 3: Rename Columns for Consistency\n",
    "df1.rename(columns={\n",
    "    \"Date\": \"Incident Date\",\n",
    "    \"Time\": \"Incident Time\",\n",
    "    \"DayOfWeek\": \"Incident Day of Week\",\n",
    "    \"Category\": \"Incident Category\",\n",
    "    \"Descript\": \"Incident Description\",\n",
    "    \"PdDistrict\": \"Police District\",\n",
    "    \"X\": \"Longitude\",\n",
    "    \"Y\": \"Latitude\"\n",
    "}, inplace=True)\n",
    "\n",
    "df2.rename(columns={\"Incident Subcategory\": \"Incident Description\"}, inplace=True)\n",
    "\n",
    "# âœ… Step 4: Keep Only Relevant Columns\n",
    "columns_to_keep = [\"Incident Date\", \"Incident Time\", \"Incident Day of Week\",\n",
    "                   \"Incident Category\", \"Incident Description\",\n",
    "                   \"Police District\", \"Latitude\", \"Longitude\"]\n",
    "\n",
    "df1 = df1[[col for col in columns_to_keep if col in df1.columns]]\n",
    "df2 = df2[[col for col in columns_to_keep if col in df2.columns]]\n",
    "\n",
    "print(\"âœ… Only relevant columns kept.\")\n",
    "\n",
    "# âœ… Step 5: Convert 'Incident Date' to datetime format\n",
    "df1[\"Incident Date\"] = pd.to_datetime(df1[\"Incident Date\"], errors=\"coerce\")\n",
    "df2[\"Incident Date\"] = pd.to_datetime(df2[\"Incident Date\"], errors=\"coerce\")\n",
    "\n",
    "# âœ… Step 6: Filter only Full Years\n",
    "df1 = df1[(df1[\"Incident Date\"] >= \"2003-01-01\") & (df1[\"Incident Date\"] <= \"2017-12-31\")]\n",
    "df2 = df2[(df2[\"Incident Date\"] >= \"2018-01-01\") & (df2[\"Incident Date\"] <= \"2023-12-31\")]\n",
    "\n",
    "print(\"âœ… Dates converted and filtered!\")\n",
    "\n",
    "# âœ… Step 7: Ensure Columns Are Exactly the Same Before Merging\n",
    "missing_cols_df1 = set(df2.columns) - set(df1.columns)\n",
    "missing_cols_df2 = set(df1.columns) - set(df2.columns)\n",
    "\n",
    "for col in missing_cols_df1:\n",
    "    df1[col] = None  # Add missing columns to df1\n",
    "\n",
    "for col in missing_cols_df2:\n",
    "    df2[col] = None  # Add missing columns to df2\n",
    "\n",
    "# âœ… Step 8: Reset Index to Avoid Merge Errors\n",
    "df1.reset_index(drop=True, inplace=True)\n",
    "df2.reset_index(drop=True, inplace=True)\n",
    "df2 = df2.loc[:, ~df2.columns.duplicated()]\n",
    "\n",
    "\n",
    "print(\"df1 data types:\\n\", df1.dtypes)\n",
    "print(\"df2 data types:\\n\", df2.dtypes)\n",
    "\n",
    "\n",
    "# âœ… Step 9: Merge the Cleaned Datasets\n",
    "df_final = pd.concat([df1, df2], ignore_index=True)\n",
    "print(f\"âœ… Datasets merged successfully! Total rows: {df_final.shape[0]}\")\n",
    "\n",
    "# âœ… Step 10: Standardize Crime Type Names\n",
    "df_final[\"Incident Category\"] = df_final[\"Incident Category\"].str.upper().str.strip()\n",
    "df_final[\"Incident Description\"] = df_final[\"Incident Description\"].str.upper().str.strip()\n",
    "\n",
    "# âœ… Step 11: Remove Duplicates\n",
    "before_dedup = df_final.shape[0]\n",
    "df_final.drop_duplicates(inplace=True)\n",
    "after_dedup = df_final.shape[0]\n",
    "print(f\"âœ… Removed {before_dedup - after_dedup} duplicate rows.\")\n",
    "\n",
    "# âœ… Step 12: Handle Missing Values\n",
    "df_final.dropna(subset=[\"Incident Category\", \"Police District\"], inplace=True)\n",
    "df_final[\"Latitude\"].fillna(df_final[\"Latitude\"].median(), inplace=True)\n",
    "df_final[\"Longitude\"].fillna(df_final[\"Longitude\"].median(), inplace=True)\n",
    "\n",
    "print(f\"âœ… Missing values handled. Total remaining rows: {df_final.shape[0]}\")\n",
    "\n",
    "# âœ… Step 13: Save Cleaned Dataset\n",
    "save_path = \"Data/SF_Crime_Data_Cleaned.csv\"\n",
    "os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "df_final.to_csv(save_path, index=False)\n",
    "\n",
    "print(\"ðŸŽ‰ Final cleaned dataset saved successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machinelearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
